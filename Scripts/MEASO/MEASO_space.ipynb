{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"12\"> **MEASO space paper** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dask.distributed import Client, progress\n",
    "import UsefulFunctions as uf\n",
    "import os\n",
    "import netCDF4 as nc\n",
    "from collections import OrderedDict\n",
    "from glob import glob\n",
    "from clef.code import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up paralellisation prior to analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/hh5/public/apps/miniconda3/envs/analysis3-21.07/lib/python3.9/site-packages/distributed/node.py:160: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 41431 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "client = Client(n_workers = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up dictionaries with supporting information for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This dictionary contains information about each variable to make production of summaries easier\n",
    "#Change the values of this dictionary as needed\n",
    "varDict = OrderedDict([\n",
    "    ('temp', {'model': 'ACCESS-ESM1-5',\n",
    "              'var_id': 'bigthetao',\n",
    "              'exp': 'historical', \n",
    "              'exp_future': 'esm-ssp585',\n",
    "              'variant': 'r10i1p1f1',\n",
    "              'freq': 'mon',\n",
    "              'long_name': 'water temperature', #Used mainly to label graphs\n",
    "              'short_name': 'temp', #Used mainly to label graphs\n",
    "              'means': r'/g/data/v45/la6889/MEASO/Summaries/Temperature/Means',\n",
    "              'percentiles': r'/g/data/v45/la6889/MEASO/Summaries/Temperature/Percentiles',\n",
    "              'std_dev': r'/g/data/v45/la6889/MEASO/Summaries/Temperature/StdDev'}),\n",
    "    ('sal', {'model': 'ACCESS-ESM1-5',\n",
    "             'var_id': 'so',\n",
    "             'exp': 'historical', \n",
    "             'exp_future': 'esm-ssp585',\n",
    "             'variant': 'r10i1p1f1',\n",
    "             'freq': 'mon',\n",
    "             'long_name': 'water salinity', \n",
    "             'short_name': 'sal', \n",
    "             'means': r'/g/data/v45/la6889/MEASO/Summaries/Salinity/Means',\n",
    "             'percentiles': r'/g/data/v45/la6889/MEASO/Summaries/Salinity/Percentiles',\n",
    "             'std_dev': r'/g/data/v45/la6889/MEASO/Summaries/Salinity/StdDev'}),\n",
    "    ('ph',{'model': 'ACCESS-ESM1-5',\n",
    "             'var_id': 'ph', #pH\n",
    "             'exp': 'historical', \n",
    "             'exp_future': 'esm-ssp585',\n",
    "             'variant': 'r10i1p1f1',\n",
    "             'freq': 'mon',\n",
    "             'long_name': 'pH', \n",
    "             'short_name': 'pH', \n",
    "             'means': r'/g/data/v45/la6889/MEASO/Summaries/pH/Means',\n",
    "             'percentiles': r'/g/data/v45/la6889/MEASO/Summaries/pH/Percentiles',\n",
    "             'std_dev': r'/g/data/v45/la6889/MEASO/Summaries/pH/StdDev'}),\n",
    "    ('pCO2',{'model': 'ACCESS-ESM1-5',\n",
    "             'var_id': 'spco2', #Surface Aqueous Partial Pressure of CO2 [Pa] - only surface available\n",
    "             'exp': 'historical', \n",
    "             'exp_future': 'esm-ssp585',\n",
    "             'variant': 'r10i1p1f1',\n",
    "             'freq': 'mon',\n",
    "             'long_name': 'partial CO2 pressure at surface', \n",
    "             'short_name': 'pCO2', \n",
    "             'means': r'/g/data/v45/la6889/MEASO/Summaries/pCO2/Means',\n",
    "             'percentiles': r'/g/data/v45/la6889/MEASO/Summaries/pCO2/Percentiles',\n",
    "             'std_dev': r'/g/data/v45/la6889/MEASO/Summaries/pCO2/StdDev'}),\n",
    "    ('mld', {'model': 'ACCESS-ESM1-5',\n",
    "             'var_id': 'mlotst', #Ocean Mixed Layer Thickness Defined by Sigma T [m]\n",
    "             'exp': 'historical', \n",
    "             'exp_future': 'esm-ssp585',\n",
    "             'variant': 'r10i1p1f1',\n",
    "             'freq': 'mon',\n",
    "             'long_name': 'mixed layer depth', \n",
    "             'short_name': 'mld', \n",
    "             'means': r'/g/data/v45/la6889/MEASO/Summaries/MLD/Means',\n",
    "             'percentiles': r'/g/data/v45/la6889/MEASO/Summaries/MLD/Percentiles',\n",
    "             'std_dev': r'/g/data/v45/la6889/MEASO/Summaries/MLD/StdDev'}),\n",
    "     ('sic', {'model': 'ACCESS-ESM1-5',\n",
    "             'var_id': 'siconc', #sea ice area fraction (% of grid cell covered by ice)\n",
    "             'exp': 'historical', \n",
    "             'exp_future': 'esm-ssp585',\n",
    "             'variant': 'r10i1p1f1',\n",
    "             'freq': 'mon',\n",
    "             'long_name': 'sea ice concentration', \n",
    "             'short_name': 'sic', \n",
    "             'means': r'/g/data/v45/la6889/MEASO/Summaries/SIC/Means',\n",
    "             'percentiles': r'/g/data/v45/la6889/MEASO/Summaries/SIC/Percentiles',\n",
    "             'std_dev': r'/g/data/v45/la6889/MEASO/Summaries/SIC/StdDev'})\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sea ice concentration:\n",
    "- siareas - sea ice area South (total area of sea ice in the Southern Hemisphere)\n",
    "- siextents - sea ice extent South (total area of Southern Hemisphere cells covered by at least 15% areal fraction of sea ice)\n",
    "- **siconc - sea ice area fraction (% of grid cell covered by ice)**\n",
    "  \n",
    "mixed layer depth:\n",
    "- **mlotst - MLD defined by sigma T (potential density)**. Max and min mean daily values also available.\n",
    "- omldamax - Ocean MLD defined by mixing scheme. Mean daily maximum\n",
    "\n",
    "partial CO2 pressure:\n",
    "- **spco2 - surface partial pressure of CO2 in sea water**\n",
    "\n",
    "PAR:\n",
    "- **rsntds - net downward shortwave flux at sea surface**\n",
    "\n",
    "cloud cover:\n",
    "- clhcalipso - Cloud area fraction in atmosphere later. % cloud cover in layer centered on 220hPa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'sic'\n",
    "\n",
    "#This dictionary contains the time periods of interest\n",
    "periods_interest = {'p1': np.arange(1890, 1911, 10),\n",
    "                    'p2': np.arange(1940, 1961, 10),\n",
    "                    'p3': np.arange(2000, 2021, 10),\n",
    "                    'p4': np.arange(2040, 2061, 10),\n",
    "                    'p5': np.arange(2090, 2101, 10)}\n",
    "\n",
    "#This dictionary contains the depths of interest\n",
    "depths_interest = {'surface': [0, 10],\n",
    "                   'pelagic': [0, 200],\n",
    "                   'krill': [0, 400]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Using clef to access ACCESS-ESM1.5 data\n",
    "The function below, `searchACCESS`, uses the `clef` library from CLEX to search CMIP6 databases. The user can create a dictionary with search requirements to extract data that meets their needs.  \n",
    "  \n",
    "This function will be used to search data that would be used as weights in calculation of summary statistics per MEASO area. Variables that can be used as weights include area (`areacello`), depth (`thkcello`) and volume (`volcello`).  \n",
    "  \n",
    "More information about the `clef` library and how to use it can be found in [COECMS GitHub repository](https://github.com/coecms/clef)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing volume per pixel using the `clef` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Volume per pixel - For weighting\n",
    "vol_file = uf.searchACCESS(var = 'volcello',\n",
    "                        model = varDict[var]['model'], \n",
    "                        freq = 'fx', \n",
    "                        exp = varDict[var]['exp'], \n",
    "                        variant = varDict[var]['variant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading volume data\n",
    "vol_df = uf.loadData(filelist = vol_file, \n",
    "                      var_name = 'volcello',\n",
    "                      SO = True, \n",
    "                      depth_range = [0, 401])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing area per pixel using the `clef` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_file = uf.searchACCESS(var = 'areacello',\n",
    "                        model = varDict[var]['model'], \n",
    "                        freq = 'fx', \n",
    "                        exp = varDict[var]['exp_future'], \n",
    "                        variant = varDict[var]['variant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_df = uf.loadData(filelist = area_file, \n",
    "                          var_name = 'areacello',\n",
    "                          SO = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Using clef to extract ACCESS-ESM 1.5 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding datasets in `historical` experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a session in CLEF to access CMIP6 data\n",
    "db = connect()\n",
    "s = Session()\n",
    "\n",
    "#Define search parameters for CLEF\n",
    "search_dict = {'variable_id': varDict[var]['var_id'], \n",
    "               'model': varDict[var]['model'], \n",
    "               'frequency': varDict[var]['freq'], \n",
    "              'experiment_id': varDict[var]['exp'],\n",
    "               'variant_label': varDict[var]['variant']}\n",
    "\n",
    "#Perform search\n",
    "df = search(s, project = 'CMIP6', latest = True, **search_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Finding datasets in `SSP585` experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define search parameters for CLEF\n",
    "search_dict = {'variable_id': varDict[var]['var_id'], \n",
    "               'model': varDict[var]['model'], \n",
    "               'frequency': varDict[var]['freq'], \n",
    "              'experiment_id': varDict[var]['exp_future'], \n",
    "               'variant_label': varDict[var]['variant']}\n",
    "\n",
    "#Perform search\n",
    "df_f = search(s, project = 'CMIP6', latest = True, **search_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a single list of files for both experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Get folder path where files are located\n",
    "folder_path = df['path'][0]\n",
    "folder_path_future = df_f['path'][0]\n",
    "\n",
    "#Extract the file names inside the folders and sort them\n",
    "filenames = sorted(glob(os.path.join(folder_path, '*.nc')))\n",
    "filenames_future = sorted(glob(os.path.join(folder_path_future, '*.nc')))\n",
    "\n",
    "#Join all file names under one variable\n",
    "filenames = np.append(filenames, filenames_future)\n",
    "\n",
    "#List filenames \n",
    "filenames\n",
    "\n",
    "#Remove variables no longer in use\n",
    "del folder_path, folder_path_future, filenames_future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separating lists into each period of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate file list into each time period of interest\n",
    "file_lists = {}\n",
    "\n",
    "if len(filenames) > 2:\n",
    "    #Loop over each period of interest\n",
    "    for key in periods_interest:\n",
    "        #Creating an empty list to hold file names\n",
    "        files = []\n",
    "        #Only keep filenames that are within the specified time period\n",
    "        for fn in filenames:\n",
    "            if (int(fn[-16:-12]) >= (periods_interest[key][0]-5)) \\\n",
    "            and (int(fn[-16:-12]) <= (periods_interest[key][-1])):\n",
    "                #Add file names to dictionary\n",
    "                files.append(fn)\n",
    "        file_lists[key] = files\n",
    "        #Remove list as it is no longer needed\n",
    "        del files\n",
    "else:\n",
    "     for key in periods_interest:\n",
    "        if periods_interest[key][0] < 2000:\n",
    "            file_lists[key] = [filenames[0]]\n",
    "        elif periods_interest[key][-1] == 2020:\n",
    "            file_lists[key] = filenames\n",
    "        else:\n",
    "            file_lists[key] = [filenames[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking data structure prior to further processing (Optional step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF4_CLASSIC data model, file format HDF5):\n",
      "    Conventions: CF-1.7 CMIP-6.2\n",
      "    activity_id: CMIP\n",
      "    branch_method: standard\n",
      "    branch_time_in_child: 0.0\n",
      "    branch_time_in_parent: 87658.0\n",
      "    creation_date: 2020-06-05T05:02:30Z\n",
      "    data_specs_version: 01.00.30\n",
      "    experiment: all-forcing simulation of the recent past\n",
      "    experiment_id: historical\n",
      "    external_variables: areacello volcello\n",
      "    forcing_index: 1\n",
      "    frequency: mon\n",
      "    further_info_url: https://furtherinfo.es-doc.org/CMIP6.CSIRO.ACCESS-ESM1-5.historical.none.r10i1p1f1\n",
      "    grid: native atmosphere N96 grid (145x192 latxlon)\n",
      "    grid_label: gn\n",
      "    history: 2020-06-05T05:02:30Z ; CMOR rewrote data to be consistent with CMIP6, CF-1.7 CMIP-6.2 and CF standards.\n",
      "    initialization_index: 1\n",
      "    institution: Commonwealth Scientific and Industrial Research Organisation, Aspendale, Victoria 3195, Australia\n",
      "    institution_id: CSIRO\n",
      "    mip_era: CMIP6\n",
      "    nominal_resolution: 250 km\n",
      "    notes: Exp: ESM-historical; Local ID: HI-14; Variable: bigthetao (['temp'])\n",
      "    parent_activity_id: CMIP\n",
      "    parent_experiment_id: piControl\n",
      "    parent_mip_era: CMIP6\n",
      "    parent_source_id: ACCESS-ESM1-5\n",
      "    parent_time_units: days since 0101-1-1\n",
      "    parent_variant_label: r1i1p1f1\n",
      "    physics_index: 1\n",
      "    product: model-output\n",
      "    realization_index: 10\n",
      "    realm: ocean\n",
      "    run_variant: forcing: GHG, Oz, SA, Sl, Vl, BC, OC, (GHG = CO2, N2O, CH4, CFC11, CFC12, CFC113, HCFC22, HFC125, HFC134a)\n",
      "    source: ACCESS-ESM1.5 (2019): \n",
      "aerosol: CLASSIC (v1.0)\n",
      "atmos: HadGAM2 (r1.1, N96; 192 x 145 longitude/latitude; 38 levels; top level 39255 m)\n",
      "atmosChem: none\n",
      "land: CABLE2.4\n",
      "landIce: none\n",
      "ocean: ACCESS-OM2 (MOM5, tripolar primarily 1deg; 360 x 300 longitude/latitude; 50 levels; top grid cell 0-10 m)\n",
      "ocnBgchem: WOMBAT (same grid as ocean)\n",
      "seaIce: CICE4.1 (same grid as ocean)\n",
      "    source_id: ACCESS-ESM1-5\n",
      "    source_type: AOGCM\n",
      "    sub_experiment: none\n",
      "    sub_experiment_id: none\n",
      "    table_id: Omon\n",
      "    table_info: Creation Date:(30 April 2019) MD5:5bd755e94c2173cb3050a0f3480f60c4\n",
      "    title: ACCESS-ESM1-5 output prepared for CMIP6\n",
      "    variable_id: bigthetao\n",
      "    variant_label: r10i1p1f1\n",
      "    version: v20200605\n",
      "    license: CMIP6 model data produced by CSIRO is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License (https://creativecommons.org/licenses/). Consult https://pcmdi.llnl.gov/CMIP6/TermsOfUse for terms of use governing CMIP6 output, including citation requirements and proper acknowledgment.  Further information about this data, including some limitations, can be found via the further_info_url (recorded as a global attribute in this file). The data producers and data providers make no warranty, either express or implied, including, but not limited to, warranties of merchantability and fitness for a particular purpose. All liabilities arising from the supply of the information (including any liability arising in negligence) are excluded to the fullest extent permitted by law.\n",
      "    cmor_version: 3.4.0\n",
      "    tracking_id: hdl:21.14100/d9b8d061-bac2-485b-9741-546cb374e87a\n",
      "    dimensions(sizes): time(120), lev(50), j(300), i(360), bnds(2), vertices(4)\n",
      "    variables(dimensions): float64 time(time), float64 time_bnds(time, bnds), float64 lev(lev), float64 lev_bnds(lev, bnds), int32 j(j), int32 i(i), float64 latitude(j, i), float64 longitude(j, i), float64 vertices_latitude(j, i, vertices), float64 vertices_longitude(j, i, vertices), float32 bigthetao(time, lev, j, i)\n",
      "    groups: \n",
      "{'Conventions': 'CF-1.7 CMIP-6.2', 'activity_id': 'CMIP', 'branch_method': 'standard', 'branch_time_in_child': 0.0, 'branch_time_in_parent': 87658.0, 'creation_date': '2020-06-05T05:02:30Z', 'data_specs_version': '01.00.30', 'experiment': 'all-forcing simulation of the recent past', 'experiment_id': 'historical', 'external_variables': 'areacello volcello', 'forcing_index': 1, 'frequency': 'mon', 'further_info_url': 'https://furtherinfo.es-doc.org/CMIP6.CSIRO.ACCESS-ESM1-5.historical.none.r10i1p1f1', 'grid': 'native atmosphere N96 grid (145x192 latxlon)', 'grid_label': 'gn', 'history': '2020-06-05T05:02:30Z ; CMOR rewrote data to be consistent with CMIP6, CF-1.7 CMIP-6.2 and CF standards.', 'initialization_index': 1, 'institution': 'Commonwealth Scientific and Industrial Research Organisation, Aspendale, Victoria 3195, Australia', 'institution_id': 'CSIRO', 'mip_era': 'CMIP6', 'nominal_resolution': '250 km', 'notes': \"Exp: ESM-historical; Local ID: HI-14; Variable: bigthetao (['temp'])\", 'parent_activity_id': 'CMIP', 'parent_experiment_id': 'piControl', 'parent_mip_era': 'CMIP6', 'parent_source_id': 'ACCESS-ESM1-5', 'parent_time_units': 'days since 0101-1-1', 'parent_variant_label': 'r1i1p1f1', 'physics_index': 1, 'product': 'model-output', 'realization_index': 10, 'realm': 'ocean', 'run_variant': 'forcing: GHG, Oz, SA, Sl, Vl, BC, OC, (GHG = CO2, N2O, CH4, CFC11, CFC12, CFC113, HCFC22, HFC125, HFC134a)', 'source': 'ACCESS-ESM1.5 (2019): \\naerosol: CLASSIC (v1.0)\\natmos: HadGAM2 (r1.1, N96; 192 x 145 longitude/latitude; 38 levels; top level 39255 m)\\natmosChem: none\\nland: CABLE2.4\\nlandIce: none\\nocean: ACCESS-OM2 (MOM5, tripolar primarily 1deg; 360 x 300 longitude/latitude; 50 levels; top grid cell 0-10 m)\\nocnBgchem: WOMBAT (same grid as ocean)\\nseaIce: CICE4.1 (same grid as ocean)', 'source_id': 'ACCESS-ESM1-5', 'source_type': 'AOGCM', 'sub_experiment': 'none', 'sub_experiment_id': 'none', 'table_id': 'Omon', 'table_info': 'Creation Date:(30 April 2019) MD5:5bd755e94c2173cb3050a0f3480f60c4', 'title': 'ACCESS-ESM1-5 output prepared for CMIP6', 'variable_id': 'bigthetao', 'variant_label': 'r10i1p1f1', 'version': 'v20200605', 'license': 'CMIP6 model data produced by CSIRO is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License (https://creativecommons.org/licenses/). Consult https://pcmdi.llnl.gov/CMIP6/TermsOfUse for terms of use governing CMIP6 output, including citation requirements and proper acknowledgment.  Further information about this data, including some limitations, can be found via the further_info_url (recorded as a global attribute in this file). The data producers and data providers make no warranty, either express or implied, including, but not limited to, warranties of merchantability and fitness for a particular purpose. All liabilities arising from the supply of the information (including any liability arising in negligence) are excluded to the fullest extent permitted by law.', 'cmor_version': '3.4.0', 'tracking_id': 'hdl:21.14100/d9b8d061-bac2-485b-9741-546cb374e87a'}\n",
      "<class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'time', size = 120\n",
      "<class 'netCDF4._netCDF4.Dimension'>: name = 'lev', size = 50\n",
      "<class 'netCDF4._netCDF4.Dimension'>: name = 'j', size = 300\n",
      "<class 'netCDF4._netCDF4.Dimension'>: name = 'i', size = 360\n",
      "<class 'netCDF4._netCDF4.Dimension'>: name = 'bnds', size = 2\n",
      "<class 'netCDF4._netCDF4.Dimension'>: name = 'vertices', size = 4\n",
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "float64 time(time)\n",
      "    bounds: time_bnds\n",
      "    units: days since 1850-01-01\n",
      "    calendar: proleptic_gregorian\n",
      "    axis: T\n",
      "    long_name: time\n",
      "    standard_name: time\n",
      "unlimited dimensions: time\n",
      "current shape = (120,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "float64 time_bnds(time, bnds)\n",
      "unlimited dimensions: time\n",
      "current shape = (120, 2)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "float64 lev(lev)\n",
      "    bounds: lev_bnds\n",
      "    units: m\n",
      "    axis: Z\n",
      "    positive: down\n",
      "    long_name: ocean depth coordinate\n",
      "    standard_name: depth\n",
      "unlimited dimensions: \n",
      "current shape = (50,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "float64 lev_bnds(lev, bnds)\n",
      "unlimited dimensions: \n",
      "current shape = (50, 2)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "int32 j(j)\n",
      "    units: 1\n",
      "    long_name: cell index along second dimension\n",
      "unlimited dimensions: \n",
      "current shape = (300,)\n",
      "filling on, default _FillValue of -2147483647 used\n",
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "int32 i(i)\n",
      "    units: 1\n",
      "    long_name: cell index along first dimension\n",
      "unlimited dimensions: \n",
      "current shape = (360,)\n",
      "filling on, default _FillValue of -2147483647 used\n",
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "float64 latitude(j, i)\n",
      "    standard_name: latitude\n",
      "    long_name: latitude\n",
      "    units: degrees_north\n",
      "    missing_value: 1e+20\n",
      "    _FillValue: 1e+20\n",
      "    bounds: vertices_latitude\n",
      "unlimited dimensions: \n",
      "current shape = (300, 360)\n",
      "filling on\n",
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "float64 longitude(j, i)\n",
      "    standard_name: longitude\n",
      "    long_name: longitude\n",
      "    units: degrees_east\n",
      "    missing_value: 1e+20\n",
      "    _FillValue: 1e+20\n",
      "    bounds: vertices_longitude\n",
      "unlimited dimensions: \n",
      "current shape = (300, 360)\n",
      "filling on\n",
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "float64 vertices_latitude(j, i, vertices)\n",
      "    units: degrees_north\n",
      "    missing_value: 1e+20\n",
      "    _FillValue: 1e+20\n",
      "unlimited dimensions: \n",
      "current shape = (300, 360, 4)\n",
      "filling on\n",
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "float64 vertices_longitude(j, i, vertices)\n",
      "    units: degrees_east\n",
      "    missing_value: 1e+20\n",
      "    _FillValue: 1e+20\n",
      "unlimited dimensions: \n",
      "current shape = (300, 360, 4)\n",
      "filling on\n",
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "float32 bigthetao(time, lev, j, i)\n",
      "    standard_name: sea_water_conservative_temperature\n",
      "    long_name: Sea Water Conservative Temperature\n",
      "    comment: Sea water conservative temperature (this should be contributed only for models using conservative temperature as prognostic field)\n",
      "    units: degC\n",
      "    original_units: K\n",
      "    history: 2020-06-05T05:02:27Z altered by CMOR: Converted units from 'K' to 'degC'. 2020-06-05T05:02:27Z altered by CMOR: replaced missing value flag (-1e+20) with standard missing value (1e+20).\n",
      "    cell_methods: area: mean where sea time: mean\n",
      "    cell_measures: area: areacello volume: volcello\n",
      "    missing_value: 1e+20\n",
      "    _FillValue: 1e+20\n",
      "    coordinates: latitude longitude\n",
      "unlimited dimensions: time\n",
      "current shape = (120, 50, 300, 360)\n",
      "filling on\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = nc.Dataset(file_lists['p1'][0])\n",
    "print(var)\n",
    "print(var.__dict__)\n",
    "[print(dim) for dim in var.dimensions.values()]\n",
    "[print(var) for var in var.variables.values()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a mask with regions of interest\n",
    "Create a mask using a netcdf file with the `creatingMask` function. Masks can be created from shapefiles using the `0_CreatingMeasoMask.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEASOregions, regionNames = uf.creatingMask('MEASO_3Dmask.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data for each period of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing data that will be used as weights\n",
    "ACCESS-ESM-1.5 has the following variables that could be used as weights in summary calculations:\n",
    "- area (`areacello`)\n",
    "- depth (`thkcello`)\n",
    "- volume (`volcello`)  \n",
    "  \n",
    "All the variables above provide data for each pixel in the area of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying functions to calculate summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception during reset or similar\n",
      "Traceback (most recent call last):\n",
      "  File \"/g/data/hh5/public/apps/miniconda3/envs/analysis3-21.10/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 697, in _finalize_fairy\n",
      "    fairy._reset(pool)\n",
      "  File \"/g/data/hh5/public/apps/miniconda3/envs/analysis3-21.10/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 893, in _reset\n",
      "    pool._dialect.do_rollback(self)\n",
      "  File \"/g/data/hh5/public/apps/miniconda3/envs/analysis3-21.10/lib/python3.9/site-packages/sqlalchemy/engine/default.py\", line 558, in do_rollback\n",
      "    dbapi_connection.rollback()\n",
      "psycopg2.OperationalError: server closed the connection unexpectedly\n",
      "\tThis probably means the server terminated abnormally\n",
      "\tbefore or while processing the request.\n",
      "\n",
      "Exception during reset or similar\n",
      "Traceback (most recent call last):\n",
      "  File \"/g/data/hh5/public/apps/miniconda3/envs/analysis3-21.10/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 697, in _finalize_fairy\n",
      "    fairy._reset(pool)\n",
      "  File \"/g/data/hh5/public/apps/miniconda3/envs/analysis3-21.10/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 893, in _reset\n",
      "    pool._dialect.do_rollback(self)\n",
      "  File \"/g/data/hh5/public/apps/miniconda3/envs/analysis3-21.10/lib/python3.9/site-packages/sqlalchemy/engine/default.py\", line 558, in do_rollback\n",
      "    dbapi_connection.rollback()\n",
      "psycopg2.OperationalError: server closed the connection unexpectedly\n",
      "\tThis probably means the server terminated abnormally\n",
      "\tbefore or while processing the request.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for per in periods_interest:\n",
    "    years = [periods_interest[per][0], \n",
    "             periods_interest[per][-1]]\n",
    "    \n",
    "    # Loading variable of interest for each time period and depth of interest\n",
    "    var_df = uf.loadData(filelist = file_lists[per], \n",
    "                      var_name = varDict[var]['var_id'],\n",
    "                      SO = True, depth_range = [0, 401],\n",
    "                      years = years, \n",
    "                      months = ['07', '06'])\n",
    "\n",
    "    #Selecting depth of interest\n",
    "    if 'lev' in var_df.coords:\n",
    "        for depth in depths_interest:\n",
    "            #Creating paths to save data and ensuring they exist\n",
    "            #Mean\n",
    "            mean_path_out = os.path.join(varDict[var]['means'], depth.title())\n",
    "            os.makedirs(mean_path_out, exist_ok = True)\n",
    "            #Create filename\n",
    "            file_out_m = os.path.join(mean_path_out, \n",
    "                                      f'WeightedMonthlyMeans_{var}_{depth}_{years[0]}-{years[-1]}.nc')\n",
    "            \n",
    "            #Standard deviation\n",
    "            std_path_out = os.path.join(varDict[var]['std_dev'], depth.title())\n",
    "            os.makedirs(std_path_out, exist_ok = True)\n",
    "            #Create filenames\n",
    "            file_out_w = os.path.join(std_path_out, \n",
    "                                      f'WeightedMonthlyMeans_{var}_{depth}_{years[0]}-{years[-1]}.nc')\n",
    "            file_out_u = os.path.join(std_path_out, \n",
    "                                      f'UnweightedMonthlyMeans_{var}_{depth}_{years[0]}-{years[-1]}.nc')\n",
    "            \n",
    "            #Percentiles\n",
    "            per_path_out = os.path.join(varDict[var]['percentiles'], depth.title())\n",
    "            os.makedirs(per_path_out, exist_ok = True)\n",
    "            #Create filename\n",
    "            file_out_p = os.path.join(per_path_out, \n",
    "                                    f'MonthlyPercentiles_{var}_{depth}_{years[0]}-{years[-1]}.nc')\n",
    "            \n",
    "            #Subsetting data to depth of interest\n",
    "            var_sub = var_df.sel(lev = slice(depths_interest[depth][0],\n",
    "                                             depths_interest[depth][-1]))\n",
    "            vol_sub = vol_df.sel(lev = slice(depths_interest[depth][0],\n",
    "                                             depths_interest[depth][-1]))\n",
    "            \n",
    "            #Summary statistics\n",
    "            #Calculate weighted means\n",
    "            weightedvarMeans = uf.weightedMeans(regions = regionNames, \n",
    "                                             var_df = var_sub, \n",
    "                                             mask_df =  MEASOregions, \n",
    "                                             weights = vol_sub)\n",
    "            #Save file\n",
    "            weightedvarMeans.to_netcdf(file_out_m)\n",
    "\n",
    "            #Calculate weighted and unweighted standard deviation\n",
    "            un_std_calcs, w_std_calcs = uf.std_dev(regions = regionNames,\n",
    "                                                var_df = var_sub, \n",
    "                                                mask_df =  MEASOregions, \n",
    "                                                weights = vol_sub,\n",
    "                                                weighted_means = weightedvarMeans)\n",
    "            #Save file\n",
    "            w_std_calcs.to_netcdf(file_out_w)\n",
    "            un_std_calcs.to_netcdf(file_out_u)\n",
    "\n",
    "            #Calculate percentiles\n",
    "            per_calcs = uf.perc_calc(regions = regionNames,\n",
    "                                  var_df = var_sub, \n",
    "                                  mask_df =  MEASOregions, \n",
    "                                  percentiles = [.2, .4, .5, .6, .8])\n",
    "            #Save file\n",
    "            per_calcs.to_netcdf(file_out_p)\n",
    "    else:\n",
    "        #Creating paths to save data and ensuring they exist\n",
    "        #Mean\n",
    "        mean_path_out = varDict[var]['means']\n",
    "        os.makedirs(mean_path_out, exist_ok = True)\n",
    "        #Create filename\n",
    "        file_out_m = os.path.join(mean_path_out, \n",
    "                                f'WeightedMonthlyMeans_{var}_{years[0]}-{years[-1]}.nc')\n",
    "        \n",
    "        #Standard deviation\n",
    "        std_path_out = varDict[var]['std_dev']\n",
    "        os.makedirs(std_path_out, exist_ok = True)\n",
    "        #Create filenames\n",
    "        file_out_w = os.path.join(std_path_out, \n",
    "                                  f'WeightedMonthlyMeans_{var}_{years[0]}-{years[-1]}.nc')\n",
    "        file_out_u = os.path.join(std_path_out, \n",
    "                                  f'UnweightedMonthlyMeans_{var}_{years[0]}-{years[-1]}.nc')\n",
    "        \n",
    "        #Percentiles\n",
    "        per_path_out = varDict[var]['percentiles']\n",
    "        os.makedirs(per_path_out, exist_ok = True)\n",
    "        #Create filename\n",
    "        file_out_p = os.path.join(per_path_out, \n",
    "                                f'MonthlyPercentiles_{var}_{years[0]}-{years[-1]}.nc')\n",
    "        \n",
    "        #No need to subset variable of interest data\n",
    "        var_sub = var_df\n",
    "        #Apply area per pixel instead of volume per pixel\n",
    "        vol_sub = area_df\n",
    "        \n",
    "        #Summary statistics\n",
    "        #Calculate weighted means\n",
    "        weightedvarMeans = uf.weightedMeans(regions = regionNames, \n",
    "                                         var_df = var_sub, \n",
    "                                         mask_df =  MEASOregions, \n",
    "                                         weights = vol_sub)\n",
    "        #Save file\n",
    "        weightedvarMeans.to_netcdf(file_out_m)\n",
    "\n",
    "        #Calculate weighted and unweighted standard deviation\n",
    "        un_std_calcs, w_std_calcs = uf.std_dev(regions = regionNames,\n",
    "                                            var_df = var_sub, \n",
    "                                            mask_df =  MEASOregions, \n",
    "                                            weights = vol_sub,\n",
    "                                            weighted_means = weightedvarMeans)\n",
    "        #Save file\n",
    "        w_std_calcs.to_netcdf(file_out_w)\n",
    "        un_std_calcs.to_netcdf(file_out_u)\n",
    "\n",
    "        #Calculate percentiles\n",
    "        per_calcs = uf.perc_calc(regions = regionNames,\n",
    "                              var_df = var_sub, \n",
    "                              mask_df =  MEASOregions, \n",
    "                              percentiles = [.2, .4, .5, .6, .8])\n",
    "        #Save file\n",
    "        per_calcs.to_netcdf(file_out_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uf.loadData(filelist = var_int, \n",
    "#                           var_name = varDict[var]['var_id'],\n",
    "#                           SO = True, depth_range = depths_interest[depth],\n",
    "#                           years = years, \n",
    "#                           months = months)\n",
    "var_name = varDict[var]['var_id']\n",
    "x= []\n",
    "if len(var_int) > 1:\n",
    "    #Looping through files and stacking them\n",
    "    for f in var_int:\n",
    "        x.append(xr.open_dataset(f, mask_and_scale = True))\n",
    "    #Concatenating files across time dimension\n",
    "    x = xr.concat(x, dim = 'time')\n",
    "else:\n",
    "    x = xr.open_dataset(var_int[0], mask_and_scale = True)\n",
    "    x = x[var_name][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
