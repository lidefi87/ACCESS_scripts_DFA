{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting sea ice in the Southern Ocean\n",
    "This script produces plots of sea ice area around the Southern Ocean using outputs from ACCESS-OM2-01.  \n",
    "**Requirements:** It is suggested you use the `conda/analysis3-20.01` (or later) kernel. This can be defined using the drop down list on the left hand corner, or type `!module load conda/analysis3` in a Python cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading relevant modules\n",
    "These modules are used to access relevant outputs and to manipulate data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This first line will show plots produced by matplotlib inside this Jupyter notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import cosima_cookbook as cc\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import netCDF4 as nc\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import os\n",
    "import calendar\n",
    "from dask.distributed import Client\n",
    "from tqdm import tqdm_notebook #to access observations\n",
    "import gc #to free up memory\n",
    "#Activate if needed\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following modules are used in map creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cmocean as cm                              # Nice colormaps\n",
    "from collections import OrderedDict               # We often use this to organise our experiments\n",
    "import cftime                                     # In case you need to work with time axes\n",
    "from glob import glob                             # If you need to search file systems\n",
    "import cartopy.crs as ccrs                        # For making maps with different projections\n",
    "import cartopy.feature as cft                     # For adding features to maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing model outputs\n",
    "Start a cluster that has multiple cores to work with. Remember that the number of cores cannot exceed the number of CPUs requested when accessing GADI.  \n",
    "If the line below does not run, skip it. The result is that the job will not be parallelised, but the script will still run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(n_workers = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access the default database of experiments from where data will be loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = cc.database.create_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses the outputs for the v140 run of ACCESS-OM2-01 which includes wind forcing. Includes experiments `01deg_jra55v140_iaf` and `01deg_jra55v140_iaf`. A list of experiments can be accessed using `cc.querying.get_experiments(session)`, you can get a detailed list of experiments by adding `all = True` argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing ACCESS-OM2 model outputs\n",
    "Once the correct experiment variables have been identified, data can be loaded into the notebook for further processing. All variables needed to do this are included below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving name of experiments of interest in variables that can be easily referred to\n",
    "exp = \"01deg_jra55v140_iaf_cycle2\"\n",
    "#Name (short name) of variable of interest\n",
    "varInt = \"aice_m\" #sea ice concentration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional variables, activate if needed. Note that because times need correction, **the start time is actually one month after the month we are interested in**. See below for explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Give the start and end dates for the analyses. The input must be given as a list, even if it is one item only.\n",
    "#Dates can be given as full date (e.g., 2010-01-01), just year and month, or just year. If multiple years are to be analysed, ensure both variables have the same length\n",
    "#Start date\n",
    "stime = [str(i)+'-02' for i in range(2000, 2001, 1)]\n",
    "#End date\n",
    "etime = [str(i)+'-01' for i in range(2001, 2002, 1)]\n",
    "#Define frequency. Remember to check frequency and variable of interest are related to each other, for example, aice_m has a monthly frequency, while aice has a daily frequency.\n",
    "freq = '1 monthly'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accessing ACCESS-OM2-01 outputs**  \n",
    "Defining function that loads data automatically using `cc.querying.getvar()` in a loop. The inputs needed are similar to those for the `cc.querying.getvar()` function, with the addition of inputs to define an area of interest.  \n",
    "The `getACCESSdata` will achieve the following:  \n",
    "- Access data for the experiment and variable of interest at the frequency requested and within the time frame specified  \n",
    "- Apply **time corrections** as midnight (00:00:00) is interpreted differently by the CICE model and the xarray package.\n",
    "    - CICE reads *2010-01-01 00:00:00* as the start of 2010-01-01, while xarray interprets it as the start of the following day (2010-01-02). To fix this problem, 12 hours are subtracted from the time dimension (also known as *time coordinate*).  \n",
    "- Latitude and longitude will be corrected in the dataset using the `geolon_t` dataset. The coordinate names are replaced by names that are more intuitive.  \n",
    "- Minimum and maximum latitudes and longitudes can be specified in the function to access specific areas of the dataset if required.  The **Southern Ocean** is defined as ocean waters south of 45S."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accessing corrected longitude data to update geographical coordinates in the array of interest\n",
    "geolon_t = cc.querying.getvar(exp, 'geolon_t', session, n = -1)\n",
    "\n",
    "#Frequency, experiment and session do not need to be specified if they were defined in the previous step\n",
    "def getACCESSdata(var, start, end, exp = exp, freq = freq, ses = session, minlon = geolon_t.yt_ocean.values.min(), maxlon = geolon_t.yt_ocean.values.max(),\\\n",
    "                  minlat = geolon_t.xt_ocean.values.min(), maxlat = geolon_t.xt_ocean.values.max()):\n",
    "    #Accessing data\n",
    "    vararray = cc.querying.getvar(exp, var, ses, frequency = freq, start_time = start, end_time = end)\n",
    "    #Applying time correction \n",
    "    vararray['time'] = vararray.time - dt.timedelta(hours = 12)\n",
    "    # assign new coordinates to SST dataset \n",
    "    #.coords extracts the values of the coordinate specified in the brackets\n",
    "    vararray.coords['ni'] = geolon_t['xt_ocean'].values\n",
    "    vararray.coords['nj'] = geolon_t['yt_ocean'].values\n",
    "    #Rename function from xarray uses dictionaries to change names. Keys refer to current names and values are the desired names\n",
    "    vararray = vararray.rename(({'ni':'xt_ocean', 'nj':'yt_ocean'}))\n",
    "    #Subsetting data to area of interest\n",
    "    #Subsetting sea ice concentration array\n",
    "    vararray = vararray.sel(yt_ocean = slice(minlon, maxlon))\n",
    "    return vararray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run-Length Encoding (RLE)**  \n",
    "Defining `rle_encode` function which identifies values in a string and the number of times a value is repeated. For example:  \n",
    "***Input*** `rle_encode(\"AAABBCCCC\")`  \n",
    "***Output*** `[[A, B, C] [3, 2, 4]]`  \n",
    "The input can be a list or a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_encode(data):\n",
    "    #Variable that will contain the values identified in the input list\n",
    "    encoding = []\n",
    "    #Variable that will contain the number of times in a row a value is identified in the input list\n",
    "    numb = []\n",
    "    #String containing the value of the previous character\n",
    "    prev_char = ''\n",
    "    #Counter\n",
    "    count = 1\n",
    "     \n",
    "    #Looping through every item in the input\n",
    "    for char in data:\n",
    "        #If item is not the same as previous character\n",
    "        if str(char) != prev_char:\n",
    "            #If previous character does exist, then append it to encoding list \n",
    "            if prev_char:\n",
    "                encoding.append(prev_char)\n",
    "                #Appending counter to number variable\n",
    "                numb.append(count)\n",
    "            #Reset counter to one before updating previous character\n",
    "            count = 1\n",
    "            #Pass current character as previous character\n",
    "            prev_char = str(char)\n",
    "        #If char and prev_char are the same\n",
    "        else:\n",
    "            #Increase counter by one\n",
    "            count += 1\n",
    "    else:\n",
    "        # Finish off the encoding\n",
    "        encoding.append(prev_char)\n",
    "        numb.append(count)\n",
    "        #Create array with values in first section and number of repeats in second section\n",
    "    z = np.array([[float(i) for i in encoding], [float(j) for j in numb]])\n",
    "    return(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying functions\n",
    "A variety of plots showing sea ice area changes in the Southern Ocean will be created below and saved in a folder using years of data shown in the graph as a unique identifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `aice_m` variable gives the mean monthly concentration of ice in a cell. In other words, this represents the monthly mean proportion of ice found in a given grid cell. To calculate the area covered by ice, the area of each cell is needed.  \n",
    "The area is saved as `area_t` and it is given by the ocean model, below we will load it to the notebook and multiply it by `aice_m` to get the total ice area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading ice area data (in m2) - Only one file needed as they will be the same regardless of the time\n",
    "IceArea = cc.querying.getvar(exp, 'area_t', session, n = 1) #ncfile = 'iceh.2010-01.nc') - A specific ncfile name can be specified\n",
    "#Accessing ACCESS 0.1deg outputs for the entire time range of interest\n",
    "SO = getACCESSdata(varInt, stime[0], etime[-1], minlon = -90, maxlon = -45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sea ice seasonality calculations\n",
    "The code below has been 'translated' from the `calc_ice_season` which is part of the `aceecostats` package developed by Michael Sumner at AAD. This section calculates annual sea ice advance and retreat as defined by Massom et al 2013 [DOI:10.1371/journal.pone.0064756]. If a pixel has at least 15% of sea ice concentration for five consecutive days, sea ice is considered to be advancing at that pixel. Day of retreat is the time when concentration remains below 15% until the end of the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Threshold refers to 15% sea ice concentration\n",
    "thres = 0.15\n",
    "#Refers to the number of consecutive days ice concentration needs to be over 15% to be considered as advancing\n",
    "ndays = 5\n",
    "#How many years are we evaluating\n",
    "year_n = len(SO.time.values)\n",
    "#Create a copy of one year of the sea ice concentration data and fill it up with zeroes\n",
    "template = copy.deepcopy(SO[1])*0\n",
    "\n",
    "#Create a copy of all SO data\n",
    "IceMat = copy.deepcopy(SO)\n",
    "#Change multilayer data array to matrix, each column will hold all data for one time step\n",
    "IceMat = IceMat.stack(z = ('xt_ocean', 'yt_ocean')).transpose()\n",
    "\n",
    "#Create an array with the same shape as the matrix to calculate sea ice advance and another one for sea ice retreat\n",
    "adv = np.zeros(IceMat.shape[0])\n",
    "ret = np.zeros(IceMat.shape[0])\n",
    "\n",
    "#Create a new matrix where all nan values will be set to -999 (based on concentration data)\n",
    "threshold = copy.deepcopy(IceMat).fillna(-999)\n",
    "#Any cells that are below the threshold will be set to zero, otherwise they are set to one\n",
    "threshold = threshold.where(threshold < thres, other = True).where(threshold >= thres, other = False)\n",
    "\n",
    "#Create new variable that contains the sum of all concentrations over one year\n",
    "rsum = threshold.sum('time')\n",
    "\n",
    "#Make an array with the time sums and make a boolean to identify zeroes\n",
    "alllt = np.array(rsum)\n",
    "alllt = np.where(alllt == 0, True, False)\n",
    "\n",
    "#Make an array with the time sums and make a boolean to identify cells with values equal to the time being analysed\n",
    "allgt = np.array(rsum)\n",
    "allgt = np.where(allgt == threshold.shape[1], True, False)\n",
    "\n",
    "#New array will have zeroes for cells that either had sum of zero or were always covered in ice\n",
    "visit = np.where((alllt == False) & (allgt == False))\n",
    "visit = visit[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in visit:\n",
    "    rl = rle_encode(threshold[i,].values)\n",
    "    for j in np.arange(0, len(rl[0])):\n",
    "        if(rl[0][j] == True and rl[1][j] >= ndays):\n",
    "            if j == 0:\n",
    "                adv[i] = 1\n",
    "            else:\n",
    "                adv[i] = sum(rl[1][0:j])\n",
    "                break\n",
    "    if(adv[i] == 0):\n",
    "        adv[i] = np.nan\n",
    "    revlengths = rl[1][::-1]\n",
    "    revvals = rl[0][::-1]\n",
    "    for k in np.arange(0, len(revlengths)):\n",
    "        if(revvals[k] == True):\n",
    "            if k == 0:\n",
    "                ret[i] = 1\n",
    "            else:\n",
    "                ret[i] = sum(revlengths[k:len(revlengths)])\n",
    "                break\n",
    "    if(ret[i] == 0):\n",
    "        ret[i] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv[np.where(alllt == True)] = np.nan\n",
    "adv[np.where(allgt == True)] = 1\n",
    "ret[np.where(alllt == True)] = np.nan\n",
    "ret[np.where(allgt == True)] = 1\n",
    "        \n",
    "adv = xr.DataArray(np.array(adv).reshape(template.shape[0], template.shape[1]), coords = [('yt_ocean', template['yt_ocean'].values), ('xt_ocean', template['xt_ocean'].values)])\n",
    "adv.to_netcdf('/g/data/v45/la6889/Calculations/SeaIceAdvance.nc')\n",
    "ret = xr.DataArray(np.array(ret).reshape(template.shape[0], template.shape[1]), coords = [('yt_ocean', template['yt_ocean'].values), ('xt_ocean', template['xt_ocean'].values)])\n",
    "ret.to_netcdf('/g/data/v45/la6889/Calculations/SeaIceRetreat.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analysis3-20.10]",
   "language": "python",
   "name": "conda-env-analysis3-20.10-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
